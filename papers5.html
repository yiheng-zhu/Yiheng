<style>
<!--
 li.MsoNormal
	{mso-style-parent:"";
	margin-bottom:.0001pt;
	text-align:justify;
	text-justify:inter-ideograph;
	font-size:10.5pt;
	font-family:"Times New Roman";
	margin-left:0cm; margin-right:0cm; margin-top:0cm}
-->
</style>

<div>
	<table border="0" id="table1" bgcolor="#FFFFFF">
<tr>
	<td valign="baseline" colspan="3" bgcolor="#ADD8E6">
		<p><b>
			<font face="Times" size="3">
				<a name="2023">Large Language Models for Protein</a>
			</font>
		</b></p>
	</td>
</tr>
		<tr>
		<td valign="baseline" colspan="3">
		<ul>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			AlphaFold-latest: Performance and structural coverage of the latest, in-development AlphaFold model.
			<b> Report</b>, 2023.
			[<a href="./papers/5/alphafold_latest_oct2023.pdf">PDF</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ESMFold: Evolutionary-scale prediction of atomic-level protein structure with a language model.
			<b> Science</b>, 2023.
			[<a href="./papers/5/ESMFold_Science_2023.pdf">PDF</a>]
			[<a href="https://github.com/facebookresearch/esm" target=_blank>Code</a>]
		</font>
	</p>
</li>


<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			xTrimoPGLM: Unified 100B-scale pre-trained transformer for deciphering the language of protein.
			<b> bioRxiv</b>, 2023.
			[<a href="./papers/5/xTrimoPGLM_bioRxiv_2023.pdf">PDF</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			Ankh: Optimized Protein Language Model Unlocks General-Purpose Modelling.
			<b> bioRxiv</b>, 2023.
			[<a href="./papers/5/Ankh_bioRxiv_2023.pdf">PDF</a>]
			[<a href="https://github.com/agemagician/Ankh/tree/main" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			CARP: Convolutions are competitive with transformers for protein sequence pretraining.
			<b> bioRxiv</b>, 2023.
			[<a href="./papers/5/CARP_bioRxiv_2023.pdf">PDF</a>]
			[<a href="https://github.com/microsoft/protein-sequence-models" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ESM-GearNet: A systematic study of joint representation learning on protein sequences and structures.
			<b> bioRxiv</b>, 2023.
			[<a href="./papers/5/ESM-GearNet_bioRxiv_2023.pdf">PDF</a>]
			[<a href="https://github.com/DeepGraphLearning/ESM-GearNet" target=_blank>Code</a>]
		</font>
	</p>
</li>


<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			SaProt: Protein language modeling with structure-aware vocabulary.
			<b> The Twelfth International Conference on Learning Representations</b>, 2023.
			[<a href="./papers/5/SAPROT_LCLR_2023.pdf">PDF</a>]
			[<a href="https://github.com/westlake-repl/SaProt" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			GearNet: Protein representation learning by geometric structure pretraining.
			<b> The Eleventh International Conference on Learning Representations</b>, 2023.
			[<a href="./papers/5/GearNet_ICLR_2023.pdf">PDF</a>]
			[<a href="https://github.com/DeepGraphLearning/GearNet" target=_blank>Code</a>]
		</font>
	</p>
</li>


<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ProGen2: Exploring the boundaries of protein language models.
			<b> Cell Systems</b>, 2023.
			[<a href="./papers/5/ProGen2_Cell Systems_2022.pdf">PDF</a>]
			[<a href="https://github.com/salesforce/progen" target=_blank>Code</a>]
		</font>
	</p>
</li>


<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ProGen: Large language models generate functional protein sequences across diverse families.
			<b> Nature Biotechnology</b>, 2023.
			[<a href="./papers/5/ProGen_Nature Biotechnology_2023.pdf">PDF</a>]
			[<a href="https://github.com/salesforce/progen" target=_blank>Code</a>]
		</font>
	</p>
</li>


<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ProtGPT2 is a deep unsupervised language model for protein design.
			<b> Nature Communications</b>, 2022.
			[<a href="./papers/5/ProtGPT2_Nature Communications_2022.pdf">PDF</a>]
			[<a href="https://huggingface.co/nferruz/ProtGPT2" target=_blank>Code</a>]
		</font>
	</p>
</li>


<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			Ontoprotein: Protein pretraining with gene ontology embedding.
			<b> International Conference on Machine Learning</b>, 2022.
			[<a href="./papers/5/OntoProtein_ICLR_2022.pdf">PDF</a>]
			[<a href="https://github.com/zjunlp/OntoProtein" target=_blank>Code</a>]
		</font>
	</p>
</li>


<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ProtTrans: Toward understanding the language of life through self-supervised learning.
			<b> IEEE Transactions on Pattern Analysis and Machine Intelligence</b>, 2022.
			[<a href="./papers/5/ProtTrans_TPAMI_2022.pdf">PDF</a>]
			[<a href="https://github.com/agemagician/ProtTrans" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ProteinBERT: A universal deep-learning model of protein sequence and function.
			<b> Bioinformatics</b>, 2022.
			[<a href="./papers/5/ProteinBERT_Bioinformatics_2022.pdf">PDF</a>]
			[<a href="https://github.com/nadavbra/protein_bert">Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			AlphaFold Protein Structure Database: Massively expanding the structural coverage of protein-sequence space with high-accuracy models.
			<b> Nucleic Acids Research</b>, 2022.
			[<a href="./papers/5/AlphaFold-Database_NAR_2022.pdf">PDF</a>]
			[<a href="https://alphafold.ebi.ac.uk">Database</a>]
		</font>
	</p>
</li>



<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			AlphaFold2: Highly accurate protein structure prediction with AlphaFold.
			<b> Nature</b>, 2021.
			[<a href="./papers/5/AlphaFold2_Nature_2021.pdf">PDF</a>]
			[<a href="https://github.com/google-deepmind/alphafold" target=_blank>Code</a>] [<a href="https://bio-web1.nscc-gz.cn/app/alphaFold2_bio">Web server</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			MSA Transformer.
			<b> International Conference on Machine Learning</b>, 2021.
			[<a href="./papers/5/MSA Transformer_International Conference on Machine Learning_2021.pdf">PDF</a>]
			[<a href="https://github.com/facebookresearch/esm" target=_blank>Code</a>] [<a href="./SI/MSA_transformer.tif">Framework</a>] [<a href="./SI/MSA_transformer_SI.pdf">Details</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ESM-1b: Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences.
			<b> Proceedings of the National Academy of Sciences</b>, 2021.
			[<a href="./papers/5/ESM-1b_PNAS_2021.pdf">PDF</a>] [<a href="https://github.com/facebookresearch/esm" target=_blank>Code</a>] [<a href="./SI/ESM-1b.tif">Framework</a>] [<a href="./SI/ESM-1b_SI.pdf">Details</a>]

		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ProSE: Learning the protein language: evolution, structure, and function.
			<b> Cell Systems </b>, 2021.
			[<a href="./papers/5/ProSE_Cell Systems_2021.pdf">PDF</a>]
			[<a href="https://github.com/tbepler/prose" target=_blank>Code</a>]

		</font>
	</p>
</li>


<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			Evaluating protein transfer learning with TAPE.
			<b> Advances in neural information processing systems</b>, 2019.
			[<a href="./papers/5/TAPE_NeurIPS_2019.pdf">PDF</a>]
			[<a href="https://github.com/songlab-cal/tape" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			Learning protein sequence embeddings using information from structure.
			<b> arXiv preprint</b>, 2019.
			[<a href="./papers/5/Bepler_Method_ICLR_2019.pdf">PDF</a>]
			[<a href="https://github.com/tbepler/protein-sequence-embedding-iclr2019" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			SeqVec: Modeling aspects of the language of life through transfer-learning protein sequences.
			<b> BMC Bioinformatics</b>, 2019.
			[<a href="./papers/5/SeqVec_BMC Bioinformatics_2019.pdf">PDF</a>]
			[<a href="https://github.com/Rostlab/SeqVec" target=_blank>Code</a>]
		</font>
	</p>
</li>




		</ul>
		</td>
		</tr>


<tr>
	<td valign="baseline" colspan="3" bgcolor="#ADD8E6">
		<p><b>
			<font face="Times" size="3">
				<a name="2023">Large Language Models for DNA</a>
			</font>
		</b></p>
	</td>
</tr>
		<tr>
		<td valign="baseline" colspan="3">
		<ul>
<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			GPN: DNA language models are powerful predictors of genome-wide variant effects.
			<b> Proceedings of the National Academy of Sciences</b>, 2023.
			[<a href="./papers/5/GPN_PANS_2023.pdf">PDF</a>]
			[<a href="https://genome.ucsc.edu/s/gbenegas/gpn-arabidopsis" target=_blank>Web Server</a>]
			[<a href="https://github.com/songlab-cal/gpn" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			GPN-MSA: An alignment-based DNA language model for genome-wide variant effect prediction.
			<b> bioRxiv</b>, 2023.
			[<a href="./papers/5/GPN-MSA_bioRxiv_2023.pdf">PDF</a>]
			[<a href="https://genome.ucsc.edu/s/gbenegas/gpn-arabidopsis" target=_blank>Web Server</a>]
			[<a href="https://github.com/songlab-cal/gpn" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			The Nucleotide Transformer: Building and evaluating robust foundation models for human genomics.
			<b> bioRxiv</b>, 2023.
			[<a href="./papers/5/Nucleotide Transformer_bioRxiv_2023.pdf">PDF</a>]
			[<a href="https://github.com/instadeepai/nucleotide-transformer" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome.
			<b> bioRxiv</b>, 2023.
			[<a href="./papers/5/DNABERT-2_bioRxiv_2023.pdf">PDF</a>]
			[<a href="https://github.com/Zhihan1996/DNABERT_2" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			DNABERT: Pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome.
			<b> Bioinformatics</b>, 2021.
			[<a href="./papers/5/DNABERT_Bioinformatics_2021.pdf">PDF</a>] [<a href="https://github.com/jerryji1993/DNABERT" target=_blank>Code</a>]

		</font>
	</p>
</li>

<tr>
	<td valign="baseline" colspan="3" bgcolor="#ADD8E6">
		<p><b>
			<font face="Times" size="3">
				<a name="2023">Large Language Models for RNA</a>
			</font>
		</b></p>
	</td>
</tr>
		<tr>
		<td valign="baseline" colspan="3">
		<ul>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			RNA-MSM: Multiple sequence alignment-based RNA language model and its application to structural inference.
			<b> Nucleic Acids Research</b>, 2023.
			[<a href="./papers/5/RNA-MSM_NAR_2023.pdf">PDF</a>]
			[<a href="https://aigene.cloudbrain2.pcl.ac.cn/#/rna-msm" target=_blank>Web Server</a>]
			[<a href="https://github.com/yikunpku/RNA-MSM" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			RNA-FM: Interpretable RNA foundation model from unannotated data for highly accurate RNA structure and function predictions.
			<b> bioRxiv</b>, 2022.
			[<a href="./papers/5/RNA-FM_bioRxiv_2022.pdf">PDF</a>]
			[<a href="https://github.com/ml4bio/RNA-FM" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			RNABERT: Informative RNA base embedding for RNA structural alignment and clustering by deep representation learning.
			<b> NAR Genomics and Bioinformatics</b>, 2022.
			[<a href="./papers/5/RNABERT_NARGB_2022.pdf">PDF</a>]
			[<a href="https://github.com/mana438/RNABERT" target=_blank>Code</a>]
		</font>
	</p>
</li>

<tr>
	<td valign="baseline" colspan="3" bgcolor="#ADD8E6">
		<p><b>
			<font face="Times" size="3">
				<a name="2023">Large Language Models for scRNA-seq data</a>
			</font>
		</b></p>
	</td>
</tr>
		<tr>
		<td valign="baseline" colspan="3">
		<ul>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			Geneformer: Transfer learning enables predictions in network biology.
			<b> Nature</b>, 2023.
			[<a href="./papers/5/Geneformer_Nature_2023.pdf">PDF</a>]
			[<a href="https://huggingface.co/ctheodoris/Geneformer" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			scFoundation: Large scale foundation model on single-cell transcriptomics.
			<b> bioRxiv</b>, 2023.
			[<a href="./papers/5/scFoundation_bioRxiv_2023.pdf">PDF</a>]
			[<a href="https://github.com/biomap-research/scFoundation" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			scGPT: Towards building a foundation model for single-cell multi-omics using generative AI.
			<b> bioRxiv</b>, 2023.
			[<a href="./papers/5/scGPT_bioRxiv_2023.pdf">PDF</a>]
			[<a href="https://github.com/bowang-lab/scGPT" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			scBERT as a large-scale pretrained deep language model for cell type annotation of single-cell RNA-seq data.
			<b> Nature Machine Intelligence</b>, 2022.
			[<a href="./papers/5/scBERT_Nature Machine Intelligence_2022.pdf">PDF</a>]
			[<a href="https://github.com/TencentAILabHealthcare/scBERT" target=_blank>Code</a>]
		</font>
	</p>
</li>

<tr>
	<td valign="baseline" colspan="3" bgcolor="#ADD8E6">
		<p><b>
			<font face="Times" size="3">
				<a name="2023">Large Language Models for gene expression data</a>
			</font>
		</b></p>
	</td>
</tr>
		<tr>
		<td valign="baseline" colspan="3">
		<ul>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			AD-AE: Adversarial deconfounding autoencoder for learning robust gene expression embeddings.
			<b> Bioinformatics</b>, 2020.
			[<a href="./papers/5/AD-AE_Bioinformatics_2020.pdf">PDF</a>]
			[<a href="https://gitlab.cs.washington.edu/abdincer/ad-ae" target=_blank>Code</a>]
		</font>
	</p>
</li>

	</table>
</div>

