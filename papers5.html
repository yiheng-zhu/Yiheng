<style>
<!--
 li.MsoNormal
	{mso-style-parent:"";
	margin-bottom:.0001pt;
	text-align:justify;
	text-justify:inter-ideograph;
	font-size:10.5pt;
	font-family:"Times New Roman";
	margin-left:0cm; margin-right:0cm; margin-top:0cm}
-->
</style>

<div>
	<table border="0" id="table1" bgcolor="#FFFFFF">
<tr>
	<td valign="baseline" colspan="3" bgcolor="#ADD8E6">
		<p><b>
			<font face="Times" size="3">
				<a name="2023">Large Language Model in Bioinformatics</a>
			</font>
		</b></p>
	</td>
</tr>
		<tr>
		<td valign="baseline" colspan="3">
		<ul>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			AlphaFold-latest: Performance and structural coverage of the latest, in-development AlphaFold model.
			<b> Report</b>, 2023.
			[<a href="./papers/5/alphafold_latest_oct2023.pdf">PDF</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ESMFold: Evolutionary-scale prediction of atomic-level protein structure with a language model.
			<b> Science</b>, 2023.
			[<a href="./papers/5/ESMFold_Science_2023.pdf">PDF</a>]
			[<a href="https://github.com/facebookresearch/esm" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			GPN: DNA language models are powerful predictors of genome-wide variant effects.
			<b> Proceedings of the National Academy of Sciences</b>, 2023.
			[<a href="./papers/5/GPN_PANS_2023.pdf">PDF</a>]
			[<a href="https://genome.ucsc.edu/s/gbenegas/gpn-arabidopsis" target=_blank>Web Server</a>]
			[<a href="https://github.com/songlab-cal/gpn" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			GPN-MSA: An alignment-based DNA language model for genome-wide variant effect prediction.
			<b> bioRxiv</b>, 2023.
			[<a href="./papers/5/GPN-MSA_bioRxiv_2023.pdf">PDF</a>]
			[<a href="https://genome.ucsc.edu/s/gbenegas/gpn-arabidopsis" target=_blank>Web Server</a>]
			[<a href="https://github.com/songlab-cal/gpn" target=_blank>Code</a>]
		</font>
	</p>
</li>


<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ProGen: Large language models generate functional protein sequences across diverse families.
			<b> Nature Biotechnology</b>, 2023.
			[<a href="./papers/5/ProGen_Nature Biotechnology_2023.pdf">PDF</a>]
			[<a href="https://github.com/salesforce/progen" target=_blank>Code</a>]
		</font>
	</p>
</li>


<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ProtGPT2 is a deep unsupervised language model for protein design.
			<b> Nature Communications</b>, 2022.
			[<a href="./papers/5/ProtGPT2_Nature Communications_2022.pdf">PDF</a>]
			[<a href="https://huggingface.co/nferruz/ProtGPT2" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ProGen2: Exploring the boundaries of protein language models.
			<b> arXiv preprint</b>, 2022.
			[<a href="./papers/5/ProGen2_arXiv preprint _2022.pdf">PDF</a>]
			[<a href="https://github.com/salesforce/progen" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			Ontoprotein: Protein pretraining with gene ontology embedding.
			<b> International Conference on Machine Learning</b>, 2022.
			[<a href="./papers/5/OntoProtein_ICLR_2022.pdf">PDF</a>]
			[<a href="https://github.com/zjunlp/OntoProtein" target=_blank>Code</a>]
		</font>
	</p>
</li>



<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ProtTrans: Toward understanding the language of life through self-supervised learning.
			<b> IEEE Transactions on Pattern Analysis and Machine Intelligence</b>, 2022.
			[<a href="./papers/5/ProtTrans_TPAMI_2022.pdf">PDF</a>]
			[<a href="https://github.com/agemagician/ProtTrans" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			AlphaFold Protein Structure Database: Massively expanding the structural coverage of protein-sequence space with high-accuracy models.
			<b> Nucleic Acids Research</b>, 2022.
			[<a href="./papers/5/AlphaFold-Database_NAR_2022.pdf">PDF</a>]
			[<a href="https://alphafold.ebi.ac.uk">Database</a>]
		</font>
	</p>
</li>



<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			AlphaFold2: Highly accurate protein structure prediction with AlphaFold.
			<b> Nature</b>, 2021.
			[<a href="./papers/5/AlphaFold2_Nature_2021.pdf">PDF</a>]
			[<a href="https://github.com/google-deepmind/alphafold" target=_blank>Code</a>] [<a href="https://bio-web1.nscc-gz.cn/app/alphaFold2_bio">Web server</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			MSA Transformer.
			<b> International Conference on Machine Learning</b>, 2021.
			[<a href="./papers/5/MSA Transformer_International Conference on Machine Learning_2021.pdf">PDF</a>]
			[<a href="https://github.com/facebookresearch/esm" target=_blank>Code</a>] [<a href="./SI/MSA_transformer.tif">Framework</a>] [<a href="./SI/MSA_transformer_SI.pdf">Details</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			ESM-1b: Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences.
			<b> Proceedings of the National Academy of Sciences</b>, 2021.
			[<a href="./papers/5/ESM-1b_PNAS_2021.pdf">PDF</a>] [<a href="https://github.com/facebookresearch/esm" target=_blank>Code</a>] [<a href="./SI/ESM-1b.tif">Framework</a>] [<a href="./SI/ESM-1b_SI.pdf">Details</a>]

		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			Evaluating protein transfer learning with TAPE.
			<b> Advances in neural information processing systems</b>, 2019.
			[<a href="./papers/5/TAPE_NeurIPS_2019.pdf">PDF</a>]
			[<a href="https://github.com/songlab-cal/tape" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			Learning protein sequence embeddings using information from structure.
			<b> arXiv preprint</b>, 2019.
			[<a href="./papers/5/Bepler_Method_ICLR_2019.pdf">PDF</a>]
			[<a href="https://github.com/tbepler/protein-sequence-embedding-iclr2019" target=_blank>Code</a>]
		</font>
	</p>
</li>

<li>
	<p style="line-height: 20px; margin-top: 10px" align="justify">
		<font face="Times" size="3">
			SeqVec: Modeling aspects of the language of life through transfer-learning protein sequences.
			<b> BMC Bioinformatics</b>, 2019.
			[<a href="./papers/5/SeqVec_BMC Bioinformatics_2019.pdf">PDF</a>]
			[<a href="https://github.com/Rostlab/SeqVec" target=_blank>Code</a>]
		</font>
	</p>
</li>

		</ul>
		</td>
		</tr>
	</table>
</div>
